---
layout: post
title: "Movie Gen: A Cast of Media Foundation Models"
category: Daily Paper
tag: 
---

> **Daily Paper**

하루에 한 논문을 30분 안에 간단하게 살펴본 결과를 기록하는 포스트입니다.

논문을 살펴볼 때 ChatGPT의 도움을 적극적으로 받으며, 따라서 포스트에 잘못된 내용이나 오류가 있을 수 있습니다.

피드백이나 의견 있으시면 언제든지 [연락](/about)주세요.

---
# 3줄 요약
- Meta에서 Movie Gen이라는 모델을 공개
- 사용자의 이미지를 기반으로 개인 맞춤형 비디오 생성, 텍스트 지시를 통한 비디오 수정, 비디오에 맞는 오디오 생성 등의 기능을 가지고 있음
- 너무 많은 내용을 다루고 있어서 트렌드를 파악하는 정도로만 살펴보았음. 나중에 기회가 되면 제대로 파악할 것

---

# 논문 정보
- 논문 제목: Movie Gen: A Cast of Media Foundation Models
- 저자: The Movie Gen team
- 소속: Meta
- 원문 링크: [arXiv 링크](https://arxiv.org/abs/2410.13720)
- 메타 블로그 포스트 : [링크](https://ai.meta.com/blog/movie-gen-media-foundation-models-generative-ai-video/)

---

# Movie Gen

- 텍스트로부터 고해상도 1080p 비디오와 동기화된 오디오를 생성할 수 있는 미디어 생성 기반 모델
- 주요 특징
	1. 텍스트-비디오 생성: 텍스트 입력에 따라 최대 16초 길이의 1080p HD 비디오를 생성.
	2. 비디오 개인화: 사용자의 이미지를 기반으로 개인 맞춤형 비디오 생성 가능.
	3. 정밀한 비디오 편집: 텍스트 지시를 통해 기존 비디오를 정밀하게 수정.
	4. 오디오 생성: 비디오와 일치하는 고품질 사운드 및 음악 생성.
	5. 대규모 파라미터 모델: 30억 개의 파라미터를 사용하는 대규모 트랜스포머 기반 모델.


---

# Abstract

우리는 Movie Gen이라는, 서로 다른 화면 비율과 동기화된 오디오를 갖춘 고품질 1080p HD 비디오를 생성하는 미디어 기반 모델들의 모음을 소개합니다. 또한, 정교한 명령에 따른 비디오 편집과 사용자의 이미지를 기반으로 한 개인 맞춤형 비디오 생성과 같은 추가 기능도 제공합니다. 우리의 모델들은 텍스트-비디오 변환, 비디오 개인화, 비디오 편집, 비디오-오디오 생성, 텍스트-오디오 생성 등 여러 작업에서 새로운 최첨단 성능을 보여줍니다.

가장 큰 비디오 생성 모델은 30억 개의 매개변수를 가진 트랜스포머로, 최대 16초 길이의 16 프레임/초(FPS) 비디오를 생성할 수 있습니다. 우리는 아키텍처, 잠재 공간, 학습 목표 및 데이터 처리 방식, 평가 프로토콜, 병렬화 기법, 추론 최적화 등 여러 기술적 혁신과 단순화 과정을 통해 대규모 데이터와 모델 크기, 학습 컴퓨팅 자원을 효과적으로 확장하는 방법을 제시합니다. 이 논문을 통해 미디어 생성 모델 연구에 대한 진전을 가속화할 수 있기를 바랍니다.


---

# 목차 및 요약

- 너무 긴 논문이라 ChatGPT가 요약을 하지 못함
